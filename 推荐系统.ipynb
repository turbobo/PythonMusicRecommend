{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推荐系统\n",
    "\n",
    "首先对音乐数据集进行数据清洗和特征提取，基于矩阵分解方式来进行音乐推荐。\n",
    "\n",
    "- 音乐数据处理\n",
    "\n",
    "读取音乐数据集，并统计其各项指标，选择有价值的信息当做我们的特征\n",
    "\n",
    "- 基于商品相似性的推荐 \n",
    "\n",
    "选择相似度计算方法，通过相似度来计算推荐结果\n",
    "\n",
    "- 基于SVD矩阵分解的推荐\n",
    "\n",
    "使用矩阵分解方法，快速高效得到推荐结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:34:54.624167Z",
     "start_time": "2017-09-26T05:34:46.420964Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sqlite3\n",
    "\n",
    "data_home = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的数据中有一部分是数据库文件，使用sqlite3工具包来帮助我们进行数据的读取，关于数据的路径这个大家可以根据自己情况来设置。\n",
    "先来看一下我们的数据长什么样子吧，对于不同格式的数据read_csv有很多参数可以来选择，例如分隔符与列名："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在数据中只需要用户，歌曲，播放量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T09:48:06.127761Z",
     "start_time": "2017-09-24T09:48:05.969929Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "triplet_dataset = pd.read_csv(filepath_or_buffer=data_home+'train_triplets.txt', \n",
    "                              sep='\\t', header=None, \n",
    "                              names=['user','song','play_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据规模还是蛮大的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(48373586, 3)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "triplet_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据占用内存与各指标格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48373586 entries, 0 to 48373585\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   user        object\n",
      " 1   song        object\n",
      " 2   play_count  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.1+ GB\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "triplet_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想更详细的了解数据的情况，可以打印其info信息，来观察不同列的类型以及整体占用内存，这里教大家一个比较实用的技巧，如果拿到的数据非常大，对数据进行处理的时候可能会出现内存溢出的错误，这里最简单的方法就是设置下数据个格式，比如将float64用float32来替代，这样可以大大节省内存开销。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T09:48:29.300568Z",
     "start_time": "2017-09-24T09:48:29.275986Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                       user                song  play_count\n0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995           1\n1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAPDEY12A81C210A9           1\n2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B           2\n3  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFNSP12AF72A0E22           1\n4  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFOVM12A58A7D494           1\n5  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBNZDC12A6D4FC103           1\n6  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBSUJE12A6D4F8CF5           2\n7  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBVFZR12A6D4F8AE3           1\n8  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXALG12A8C13C108           1\n9  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBXHDL12A81C204C0           1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>song</th>\n      <th>play_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n      <td>SOAKIMP12A8C130995</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n      <td>SOAPDEY12A81C210A9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n      <td>SOBBMDR12A8C13253B</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n      <td>SOBFNSP12AF72A0E22</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n      <td>SOBFOVM12A58A7D494</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n      <td>SOBNZDC12A6D4FC103</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n      <td>SOBSUJE12A6D4F8CF5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n      <td>SOBVFZR12A6D4F8AE3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n      <td>SOBXALG12A8C13C108</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n      <td>SOBXHDL12A81C204C0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "triplet_dataset.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对每一个用户，分别统计他的播放总量\n",
    "\n",
    "数据中有用户的编号，歌曲编号，已经用户对该歌曲播放的次数。\n",
    "有了基础数据之后，我们还可以统计出关于用户与歌曲的各项指标，例如对每一个用户，分别统计他的播放总量，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T10:00:40.238849Z",
     "start_time": "2017-09-24T09:57:54.875213Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "output_dict = {}\n",
    "with open(data_home+'train_triplets.txt') as f:\n",
    "    for line_number, line in enumerate(f):\n",
    "        #找到当前的用户\n",
    "        user = line.split('\\t')[0]\n",
    "        #得到其播放量数据\n",
    "        play_count = int(line.split('\\t')[2])\n",
    "        #如果字典中已经有该用户信息，在其基础上增加当前的播放量\n",
    "        if user in output_dict:\n",
    "            play_count +=output_dict[user]\n",
    "            output_dict.update({user:play_count})\n",
    "        output_dict.update({user:play_count})\n",
    "# 统计 用户-总播放量\n",
    "output_list = [{'user':k,'play_count':v} for k,v in output_dict.items()]\n",
    "#转换成DF格式\n",
    "play_count_df = pd.DataFrame(output_list)\n",
    "#排序\n",
    "play_count_df = play_count_df.sort_values(by = 'play_count', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建一个字典结构来统计不同用户分别播放的总数，这需要我们把数据集遍历一遍。当我们的数据集比较庞大的时候，每一步操作都可能花费较长时间，后续操作中如果稍有不慎可能还得重头再来一遍，这就得不偿失了，最好还是把中间结果保存下来，既然我们已经把结果转换成df格式，直接使用to_csv()函数就可以完成保存的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "play_count_df.to_csv(path_or_buf='user_playcount_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对于每一首歌，分别统计它的播放总量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T10:08:50.652416Z",
     "start_time": "2017-09-24T10:05:53.721519Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#统计方法跟上述类似\n",
    "output_dict = {}\n",
    "with open(data_home+'train_triplets.txt') as f:\n",
    "    for line_number, line in enumerate(f):\n",
    "        #找到当前歌曲\n",
    "        song = line.split('\\t')[1]\n",
    "        #找到当前播放次数\n",
    "        play_count = int(line.split('\\t')[2])\n",
    "        #统计每首歌曲被播放的总次数\n",
    "        if song in output_dict:\n",
    "            play_count +=output_dict[song]\n",
    "            output_dict.update({song:play_count})\n",
    "        output_dict.update({song:play_count})\n",
    "output_list = [{'song':k,'play_count':v} for k,v in output_dict.items()]\n",
    "#转换成df格式\n",
    "song_count_df = pd.DataFrame(output_list)\n",
    "song_count_df = song_count_df.sort_values(by = 'play_count', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "song_count_df.to_csv(path_or_buf='song_playcount_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 看看目前的排行情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T10:08:54.987662Z",
     "start_time": "2017-09-24T10:08:53.518248Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                       user  play_count\n0  093cb74eb3c517c5179ae24caf0ebec51b24d2a2       13132\n1  119b7c88d58d0c6eb051365c103da5caf817bea6        9884\n2  3fa44653315697f42410a30cb766a4eb102080bb        8210\n3  a2679496cd0af9779a92a13ff7c6af5c81ea8c7b        7015\n4  d7d2d888ae04d16e994d6964214a1de81392ee04        6494\n5  4ae01afa8f2430ea0704d502bc7b57fb52164882        6472\n6  b7c24f770be6b802805ac0e2106624a517643c17        6150\n7  113255a012b2affeab62607563d03fbdf31b08e7        5656\n8  6d625c6557df84b60d90426c0116138b617b9449        5620\n9  99ac3d883681e21ea68071019dba828ce76fe94d        5602",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>play_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>093cb74eb3c517c5179ae24caf0ebec51b24d2a2</td>\n      <td>13132</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>119b7c88d58d0c6eb051365c103da5caf817bea6</td>\n      <td>9884</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3fa44653315697f42410a30cb766a4eb102080bb</td>\n      <td>8210</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a2679496cd0af9779a92a13ff7c6af5c81ea8c7b</td>\n      <td>7015</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>d7d2d888ae04d16e994d6964214a1de81392ee04</td>\n      <td>6494</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4ae01afa8f2430ea0704d502bc7b57fb52164882</td>\n      <td>6472</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>b7c24f770be6b802805ac0e2106624a517643c17</td>\n      <td>6150</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>113255a012b2affeab62607563d03fbdf31b08e7</td>\n      <td>5656</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>6d625c6557df84b60d90426c0116138b617b9449</td>\n      <td>5620</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>99ac3d883681e21ea68071019dba828ce76fe94d</td>\n      <td>5602</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "play_count_df = pd.read_csv(filepath_or_buffer='user_playcount_df.csv')\n",
    "play_count_df.head(n =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T10:09:06.800300Z",
     "start_time": "2017-09-24T10:09:06.427869Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 song  play_count\n0  SOBONKR12A58A7A7E0      726885\n1  SOAUWYT12A81C206F1      648239\n2  SOSXLTC12AF72A7F54      527893\n3  SOFRQTD12A81C233C0      425463\n4  SOEGIYH12A6D4FC0E3      389880\n5  SOAXGDH12A8C13F8A1      356533\n6  SONYKOW12AB01849C9      292642\n7  SOPUCYA12A8C13A694      274627\n8  SOUFTBI12AB0183F65      268353\n9  SOVDSJC12A58A7A271      244730",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song</th>\n      <th>play_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SOBONKR12A58A7A7E0</td>\n      <td>726885</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SOAUWYT12A81C206F1</td>\n      <td>648239</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SOSXLTC12AF72A7F54</td>\n      <td>527893</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SOFRQTD12A81C233C0</td>\n      <td>425463</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SOEGIYH12A6D4FC0E3</td>\n      <td>389880</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>SOAXGDH12A8C13F8A1</td>\n      <td>356533</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>SONYKOW12AB01849C9</td>\n      <td>292642</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>SOPUCYA12A8C13A694</td>\n      <td>274627</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>SOUFTBI12AB0183F65</td>\n      <td>268353</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SOVDSJC12A58A7A271</td>\n      <td>244730</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "song_count_df = pd.read_csv(filepath_or_buffer='song_playcount_df.csv')\n",
    "song_count_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最受欢迎的一首歌曲有726885次播放。\n",
    "刚才大家也看到了，这个音乐数据量集十分庞大，考虑到执行过程的时间消耗以及矩阵稀疏性问题，我们依据播放量指标对数据集进行了截取。因为有些注册用户可能只是关注了一下之后就不再登录平台，这些用户对我们建模不会起促进作用，反而增大了矩阵的稀疏性。对于歌曲也是同理，可能有些歌曲根本无人问津。由于之前已经对用户与歌曲播放情况进行了排序，所以我们分别选择了其中的10W名用户和3W首歌曲，关于截取的合适比例大家也可以通过观察选择数据的播放量占总体的比例来设置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取其中一部分数（按大小排好序的了，这些应该是比较重要的数据），作为我们的实验数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T10:16:05.763243Z",
     "start_time": "2017-09-24T10:16:05.700186Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "40.8807280500655\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#10W名用户的播放量占总体的比例\n",
    "total_play_count = sum(song_count_df.play_count)\n",
    "print ((float(play_count_df.head(n=100000).play_count.sum())/total_play_count)*100)\n",
    "play_count_subset = play_count_df.head(n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T10:26:37.537061Z",
     "start_time": "2017-09-24T10:26:37.528055Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "78.39315366645269"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "(float(song_count_df.head(n=30000).play_count.sum())/total_play_count)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T10:26:38.311410Z",
     "start_time": "2017-09-24T10:26:38.306426Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "song_count_subset = song_count_df.head(n=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前3W首歌的播放量占到了总体的78.39%\n",
    "现在已经有了这10W名忠实用户和3W首经典歌曲，接下来我们就要对原始数据集进行过滤清洗，说白了就是在原始数据集中剔除掉不包含这些用户以及歌曲的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取10W个用户，3W首歌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T10:26:39.337554Z",
     "start_time": "2017-09-24T10:26:39.326529Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "user_subset = list(play_count_subset.user)\n",
    "song_subset = list(song_count_subset.song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过滤掉其他用户数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T10:30:23.563673Z",
     "start_time": "2017-09-24T10:27:22.711377Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#读取原始数据集\n",
    "triplet_dataset = pd.read_csv(filepath_or_buffer=data_home+'train_triplets.txt',sep='\\t', \n",
    "                              header=None, names=['user','song','play_count'])\n",
    "#只保留有这10W名用户的数据，其余过滤掉\n",
    "triplet_dataset_sub = triplet_dataset[triplet_dataset.user.isin(user_subset) ]\n",
    "del(triplet_dataset)\n",
    "#只保留有这3W首歌曲的数据，其余也过滤掉\n",
    "triplet_dataset_sub_song = triplet_dataset_sub[triplet_dataset_sub.song.isin(song_subset)]\n",
    "del(triplet_dataset_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "triplet_dataset_sub_song.to_csv(path_or_buf=data_home+'triplet_dataset_sub_song.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当前我们的数据量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T10:32:35.248710Z",
     "start_time": "2017-09-24T10:32:35.241709Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "triplet_dataset_sub_song.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据样本个数此时只有原来的1/4不到，但是我们过滤掉的样本都是稀疏数据不利于建模，所以当拿到了数据之后对数据进行清洗和预处理工作还是非常有必要的，不单单提升计算的速度，还会影响最终的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T10:33:25.958644Z",
     "start_time": "2017-09-24T10:33:25.939631Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "triplet_dataset_sub_song.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加入音乐详细信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们目前拿到的数据只有播放次数，可利用的信息实在太少了，对每首歌来说正常情况都应该有一份详细信息，例如歌手，发布时间，主题等，这些信息都存在一份数据库格式文件中，接下来我们就通过sqlite工具包来读取这些数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T13:48:12.545636Z",
     "start_time": "2017-09-24T13:48:12.536631Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(data_home+'track_metadata.db')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "track_metadata_df = pd.read_sql(con=conn, sql='select * from songs')\n",
    "track_metadata_df_sub = track_metadata_df[track_metadata_df.song_id.isin(song_subset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T14:00:17.841834Z",
     "start_time": "2017-09-24T14:00:17.450258Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "track_metadata_df_sub.to_csv(path_or_buf=data_home+'track_metadata_df_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T14:00:26.155770Z",
     "start_time": "2017-09-24T14:00:26.149763Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "track_metadata_df_sub.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们现有的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:35:13.855787Z",
     "start_time": "2017-09-26T05:35:00.267829Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "triplet_dataset_sub_song = pd.read_csv(filepath_or_buffer=data_home+'triplet_dataset_sub_song.csv',encoding = \"ISO-8859-1\")\n",
    "track_metadata_df_sub = pd.read_csv(filepath_or_buffer=data_home+'track_metadata_df_sub.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "triplet_dataset_sub_song.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "track_metadata_df_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 清洗数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去除掉无用的和重复的，数据清洗是很重要的一步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:35:26.643464Z",
     "start_time": "2017-09-26T05:35:14.956760Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 去掉无用的信息\n",
    "del(track_metadata_df_sub['track_id'])\n",
    "del(track_metadata_df_sub['artist_mbid'])\n",
    "# 去掉重复的\n",
    "track_metadata_df_sub = track_metadata_df_sub.drop_duplicates(['song_id'])\n",
    "# 将这份音乐信息数据和我们之前的播放数据整合到一起\n",
    "triplet_dataset_sub_song_merged = pd.merge(triplet_dataset_sub_song, track_metadata_df_sub, how='left', left_on='song', right_on='song_id')\n",
    "# 可以自己改变列名\n",
    "triplet_dataset_sub_song_merged.rename(columns={'play_count':'listen_count'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:35:31.415206Z",
     "start_time": "2017-09-26T05:35:29.271749Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 去掉不需要的指标\n",
    "del(triplet_dataset_sub_song_merged['song_id'])\n",
    "del(triplet_dataset_sub_song_merged['artist_id'])\n",
    "del(triplet_dataset_sub_song_merged['duration'])\n",
    "del(triplet_dataset_sub_song_merged['artist_familiarity'])\n",
    "del(triplet_dataset_sub_song_merged['artist_hotttnesss'])\n",
    "del(triplet_dataset_sub_song_merged['track_7digitalid'])\n",
    "del(triplet_dataset_sub_song_merged['shs_perf'])\n",
    "del(triplet_dataset_sub_song_merged['shs_work'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搞定数据，来看看它长什么样子吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T14:01:44.587532Z",
     "start_time": "2017-09-24T14:01:44.561014Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "triplet_dataset_sub_song_merged.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在的数据看起来工整多了，不光有用户对某个音乐作品的播放量，还有该音乐作品的名字和发布专辑，以及作者名字和发布时间。\n",
    "现在我们只是大体了解了数据中各个指标的含义，对其具体内容还没有加以分析，我们在之前介绍推荐系统的时候提到过冷启动问题，就是一个新用户来了不知道给他推荐什么好，这时候就可以利用排行榜单了。可以统计最受欢迎的歌曲和歌手是哪些："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 展示最流行的歌曲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#按歌曲名字来统计其播放量的总数\n",
    "popular_songs = triplet_dataset_sub_song_merged[['title','listen_count']].groupby('title').sum().reset_index()\n",
    "#对结果进行排序\n",
    "popular_songs_top_20 = popular_songs.sort_values('listen_count', ascending=False).head(n=20)\n",
    "\n",
    "#转换成list格式方便画图\n",
    "objects = (list(popular_songs_top_20['title']))\n",
    "#设置位置\n",
    "y_pos = np.arange(len(objects))\n",
    "#对应结果值\n",
    "performance = list(popular_songs_top_20['listen_count'])\n",
    "#绘图\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects, rotation='vertical')\n",
    "plt.ylabel('Item count')\n",
    "plt.title('Most popular songs')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里展示了最受欢迎的歌曲，使用groupby函数可以很方便的对每首歌曲统计其播放情况，我们求的是总和也就是总播放量。这份排行数据就可以当做最受欢迎歌曲来推荐给用户了。\n",
    "同样的方法我们还可以对专辑和歌手的播放情况分别进行统计："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最受欢迎的releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T14:31:19.717845Z",
     "start_time": "2017-09-24T14:31:14.004246Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#按专辑名字来统计播放总量\n",
    "popular_release = triplet_dataset_sub_song_merged[['release','listen_count']].groupby('release').sum().reset_index()\n",
    "#排序\n",
    "popular_release_top_20 = popular_release.sort_values('listen_count', ascending=False).head(n=20)\n",
    "\n",
    "objects = (list(popular_release_top_20['release']))\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = list(popular_release_top_20['listen_count'])\n",
    "#绘图 \n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects, rotation='vertical')\n",
    "plt.ylabel('Item count')\n",
    "plt.title('Most popular Release')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最受欢迎的歌手"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T14:34:20.212228Z",
     "start_time": "2017-09-24T14:34:15.653934Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#按歌手来统计其播放总量\n",
    "popular_artist = triplet_dataset_sub_song_merged[['artist_name','listen_count']].groupby('artist_name').sum().reset_index()\n",
    "#排序\n",
    "popular_artist_top_20 = popular_artist.sort_values('listen_count', ascending=False).head(n=20)\n",
    "\n",
    "objects = (list(popular_artist_top_20['artist_name']))\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = list(popular_artist_top_20['listen_count'])\n",
    "#绘图 \n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects, rotation='vertical')\n",
    "plt.ylabel('Item count')\n",
    "plt.title('Most popular Artists')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户播放过歌曲量的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T14:55:04.690241Z",
     "start_time": "2017-09-24T14:54:59.848292Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "user_song_count_distribution = triplet_dataset_sub_song_merged[['user','title']].groupby('user').count().reset_index().sort_values(\n",
    "by='title',ascending = False)\n",
    "user_song_count_distribution.title.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-24T15:11:28.003535Z",
     "start_time": "2017-09-24T15:11:27.461150Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x = user_song_count_distribution.title\n",
    "n, bins, patches = plt.hist(x, 50, facecolor='green', alpha=0.75)\n",
    "plt.xlabel('Play Counts')\n",
    "plt.ylabel('Num of Users')\n",
    "plt.title(r'$\\mathrm{Histogram\\ of\\ User\\ Play\\ Count\\ Distribution}\\ $')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "绝大多数用户播放歌曲的数量在100左右，关于数据的处理和介绍已经给大家都分析过了，接下来我们要做的就是构建一个能实际进行推荐的程序了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始构建推荐系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import Recommenders as Recommenders\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 简单暴力，排行榜单推荐，对新用户来说解决冷启动问题\n",
    "\n",
    "最简单的推荐方式就是排行榜单了，这里我们创建了一个函数，需要我们传入的是原始数据，用户列名，待统计的指标（例如按歌曲名字，歌手名字，专辑名字。选择统计哪项指标得到的排行榜单）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "triplet_dataset_sub_song_merged_set = triplet_dataset_sub_song_merged\n",
    "train_data, test_data = train_test_split(triplet_dataset_sub_song_merged_set, test_size = 0.40, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def create_popularity_recommendation(train_data, user_id, item_id):\n",
    "    #根据指定的特征来统计其播放情况，可以选择歌曲名，专辑名，歌手名\n",
    "    train_data_grouped = train_data.groupby([item_id]).agg({user_id: 'count'}).reset_index()\n",
    "    #为了直观展示，我们用得分来表示其结果\n",
    "    train_data_grouped.rename(columns = {user_id: 'score'},inplace=True)\n",
    "    \n",
    "    #排行榜单需要排序\n",
    "    train_data_sort = train_data_grouped.sort_values(['score', item_id], ascending = [0,1])\n",
    "    \n",
    "    #加入一项排行等级，表示其推荐的优先级\n",
    "    train_data_sort['Rank'] = train_data_sort['score'].rank(ascending=0, method='first')\n",
    "        \n",
    "    #返回指定个数的推荐结果\n",
    "    popularity_recommendations = train_data_sort.head(20)\n",
    "    return popularity_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "recommendations = create_popularity_recommendation(triplet_dataset_sub_song_merged,'user','title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到推荐结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "返回了一份前20的歌曲排行榜单，其中的得分这里只是进行了简单的播放计算，在设计的时候也可以综合考虑更多的指标，比如综合计算歌曲发布年份，歌手的流行程度等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于歌曲相似度的推荐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来就要进行相似度的计算来推荐歌曲了，为了加快代码的运行速度，选择了其中一部分数据来进行实验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "song_count_subset = song_count_df.head(n=5000)\n",
    "user_subset = list(play_count_subset.user)\n",
    "song_subset = list(song_count_subset.song)\n",
    "triplet_dataset_sub_song_merged_sub = triplet_dataset_sub_song_merged[triplet_dataset_sub_song_merged.song.isin(song_subset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "triplet_dataset_sub_song_merged_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算相似度得到推荐结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import Recommenders as Recommenders\n",
    "train_data, test_data = train_test_split(triplet_dataset_sub_song_merged_sub, test_size = 0.30, random_state=0)\n",
    "is_model = Recommenders.item_similarity_recommender_py()\n",
    "is_model.create(train_data, 'user', 'title')\n",
    "user_id = list(train_data.user)[7]\n",
    "user_items = is_model.get_user_items(user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "心的同学应该观察到了，我们首先导入了Recommenders，像是一个自定义的工具包，这里就包括了我们接下来要使用的所有函数，由于接下来进行计算的代码量较大，直接在notebook中进行展示比较麻烦，所有我们自己写了一个.py文件，所有的实际计算操作都在这里完成了。\n",
    "大家在实践这份代码的时候，可以选择一个合适的IDE，因为notebook并不支持debug操作。拿到了一份陌生的代码而且量又比较大的时候，最好先通过debug的方式一行代码一行代码来执行，这样可以更清晰的熟悉整个函数做了一件什么事，如果直接看整体对于初学的同学们来说可能会有点难度，建议大家选择一个趁手的IDE例如pycharm,eclipse等都是不错的。"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整体的代码量还是比较多，我先从整体上介绍这段代码做了一件什么事，大家在自己玩的时候最好按照我之前说的还是debug一遍更舒服。首先我们要针对某一个用户进行推荐，那必然得先得到他都听过哪些歌曲，通过这些已被听过的歌曲跟整个数据集中的歌曲进行对比，看哪些歌曲跟用户已听过的比较类似，推荐的就是这些类似的。如何计算呢？例如当前用户听过了66首歌曲，整个数据集中有4879个歌曲，我们要做的就是构建一个[66,4879]的矩阵，其中每一个值表示用户听过的每一个歌曲和数据集中每一个歌曲的相似度。这里使用Jaccard相似系数，矩阵中[i,j]的含义就是用户听过的第i首歌曲这些歌曲被哪些人听过，比如有3000人听过，数据集中的j歌曲被哪些人听过，比如有5000人听过。Jaccard相似系数就要求：\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "说白了就是如果两个歌曲很相似，那其受众应当是一致的，交集/并集的比例应该比较大，如果两个歌曲没啥相关性，其值应当就比较小了。\n",
    "上述代码中计算了矩阵[66,4879]中每一个位置的值应当是多少，在最后推荐的时候我们还应当注意一件事对于数据集中每一个待推荐的歌曲都需要跟该用户所有听过的歌曲计算其Jaccard值，例如歌曲j需要跟用户听过的66个歌曲计算其值，最终是否推荐的得分值还得进行处理，即把这66个值加在一起，最终求一个平均值，来代表该歌曲的推荐得分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#执行推荐\n",
    "is_model.recommend(user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于矩阵分解（SVD）的推荐\n",
    "\n",
    "相似度计算的方法看起来比较简单就是实现出来，但是当数据较大的时候计算的时间消耗实在太大了，对每一个用户都需要多次遍历整个数据集来进行计算，矩阵分解的方法是当下更常使用的方法。\n",
    "\n",
    "奇异值分解(Singular Value Decomposition，SVD)是矩阵分解中一个经典方法，接下来我们的推荐就可以SVD来进行计算，奇异值分解的基本出发点跟我们之前讲的隐语义模型有些类似都是将大矩阵转换成小矩阵的组合,基本形式如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.png\" style=\"width:550px;height:280px;float:left\">\n",
    "<img src=\"5.png\" style=\"width:350px;height:280px;float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对矩阵进行SVD分解，将得到USV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2.png\" style=\"width:500px;height:380px;float:left\"><img src=\"3.png\" style=\"width:400px;height:200px;float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重新计算 U*S*V的结果得到A2 来比较下A2和A的差异，看起来差异是有的，但是并不大，所以我们可以近似来代替"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"4.png\" style=\"width:330px;height:220px;float:left\">\n",
    "<img src=\"5.png\" style=\"width:330px;height:220px;float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"6.png\" style=\"width:650px;height:480px;float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"7.png\" style=\"width:650px;height:480px;float:left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在SVD中我们所需的数据是用户对商品的打分，但是我们现在的数据集中只有用户播放歌曲的情况并没有实际的打分值，所以我们还得自己来定义一下用户对每个歌曲的评分值。如果一个用户喜欢某个歌曲，那应该经常播放这个歌曲，相反如果不喜欢某个歌曲，那播放次数肯定就比较少了。\n",
    "用户对歌曲的打分值，定义为：用户播放该歌曲数量/该用户播放总量。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:35:54.570454Z",
     "start_time": "2017-09-26T05:35:47.751153Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "triplet_dataset_sub_song_merged_sum_df = triplet_dataset_sub_song_merged[['user','listen_count']].groupby('user').sum().reset_index()\n",
    "triplet_dataset_sub_song_merged_sum_df.rename(columns={'listen_count':'total_listen_count'},inplace=True)\n",
    "triplet_dataset_sub_song_merged = pd.merge(triplet_dataset_sub_song_merged,triplet_dataset_sub_song_merged_sum_df)\n",
    "triplet_dataset_sub_song_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "triplet_dataset_sub_song_merged['fractional_play_count'] = triplet_dataset_sub_song_merged['listen_count']/triplet_dataset_sub_song_merged['total_listen_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大概是这样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:35:59.313745Z",
     "start_time": "2017-09-26T05:35:56.374249Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "triplet_dataset_sub_song_merged[triplet_dataset_sub_song_merged.user =='d6589314c0a9bcbca4fee0c93b14bc402363afea'][['user','song','listen_count','fractional_play_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:36:21.506614Z",
     "start_time": "2017-09-26T05:36:02.556438Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "small_set = triplet_dataset_sub_song_merged\n",
    "user_codes = small_set.user.drop_duplicates().reset_index()\n",
    "song_codes = small_set.song.drop_duplicates().reset_index()\n",
    "user_codes.rename(columns={'index':'user_index'}, inplace=True)\n",
    "song_codes.rename(columns={'index':'song_index'}, inplace=True)\n",
    "song_codes['so_index_value'] = list(song_codes.index)\n",
    "user_codes['us_index_value'] = list(user_codes.index)\n",
    "small_set = pd.merge(small_set,song_codes,how='left')\n",
    "small_set = pd.merge(small_set,user_codes,how='left')\n",
    "mat_candidate = small_set[['us_index_value','so_index_value','fractional_play_count']]\n",
    "data_array = mat_candidate.fractional_play_count.values\n",
    "row_array = mat_candidate.us_index_value.values\n",
    "col_array = mat_candidate.so_index_value.values\n",
    "\n",
    "data_sparse = coo_matrix((data_array, (row_array, col_array)),dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:36:23.566197Z",
     "start_time": "2017-09-26T05:36:23.558192Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面代码先根据用户进行分组，计算每个用户的总的播放总量，然后用每首歌的播放总量相处，得到每首歌的分值，最后一列特征fractional_play_count就是用户对每首歌曲的评分值。\n",
    "有了评分值之后就可以来构建矩阵了，这里有一些小问题需要处理一下，原始数据中无论是用户ID还是歌曲ID都是很长一串，这表达起来不太方便，需要重新对其制作索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:36:28.138686Z",
     "start_time": "2017-09-26T05:36:28.108662Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "user_codes[user_codes.user =='2a2f776cbac6df64d6cb505e7e834e01684673b6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用SVD方法来进行矩阵分解\n",
    "\n",
    "矩阵构造好了之后我们就要执行SVD矩阵分解了，这里还需要一些额外的工具包来帮助我们完成计算，scipy就是其中一个好帮手了，里面已经封装好了SVD计算方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:36:35.965832Z",
     "start_time": "2017-09-26T05:36:31.399367Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import math as mt\n",
    "from scipy.sparse.linalg import * #used for matrix multiplication\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.sparse import csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:38:22.051129Z",
     "start_time": "2017-09-26T05:38:22.026115Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_svd(urm, K):\n",
    "    U, s, Vt = svds(urm, K)\n",
    "\n",
    "    dim = (len(s), len(s))\n",
    "    S = np.zeros(dim, dtype=np.float32)\n",
    "    for i in range(0, len(s)):\n",
    "        S[i,i] = mt.sqrt(s[i])\n",
    "\n",
    "    U = csc_matrix(U, dtype=np.float32)\n",
    "    S = csc_matrix(S, dtype=np.float32)\n",
    "    Vt = csc_matrix(Vt, dtype=np.float32)\n",
    "    \n",
    "    return U, S, Vt\n",
    "\n",
    "def compute_estimated_matrix(urm, U, S, Vt, uTest, K, test):\n",
    "    rightTerm = S*Vt \n",
    "    max_recommendation = 250\n",
    "    estimatedRatings = np.zeros(shape=(MAX_UID, MAX_PID), dtype=np.float16)\n",
    "    recomendRatings = np.zeros(shape=(MAX_UID,max_recommendation ), dtype=np.float16)\n",
    "    for userTest in uTest:\n",
    "        prod = U[userTest, :]*rightTerm\n",
    "        estimatedRatings[userTest, :] = prod.todense()\n",
    "        recomendRatings[userTest, :] = (-estimatedRatings[userTest, :]).argsort()[:max_recommendation]\n",
    "    return recomendRatings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在执行SVD的时候需要我们额外指定一个指标K值，其含义就是我们选择前多少个特征值来做近似代表，也就是S矩阵中的数量。如果K值较大整体的计算效率会慢一些但是会更接近真实结果，这个值还需要我们自己来衡量一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:38:41.670740Z",
     "start_time": "2017-09-26T05:38:23.522055Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "K=50\n",
    "urm = data_sparse\n",
    "MAX_PID = urm.shape[1]\n",
    "MAX_UID = urm.shape[0]\n",
    "\n",
    "U, S, Vt = compute_svd(urm, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们选择K值等于50，其中PID表示我们最开始选择的部分歌曲，UID表示我们选择的部分用户。\n",
    "\n",
    "执行过程中，可以打印出各个矩阵的大小，这里强烈建议大家将代码复制到IDE中，打上断点一行一行的走下面，观察其中每一个变量的值，这对理解整个流程是非常有帮助的。\n",
    "\n",
    "接下来我们需要选择待测试用户了：\n",
    "\n",
    "uTest = [4,5,6,7,8,873,23]\n",
    "\n",
    "随便选择一些用户就好，这里表示用户的索引编号，接下来需要对每一个用户计算其对我们候选集中3W首歌曲的喜好程度，说白了就是估计他对这3W首歌的评分值应该等于多少，前面我们通过SVD矩阵分解已经计算所需各个小矩阵了，接下来把其还原回去就可以啦："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:38:44.738094Z",
     "start_time": "2017-09-26T05:38:44.485691Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "uTest = [4,5,6,7,8,873,23]\n",
    "\n",
    "uTest_recommended_items = compute_estimated_matrix(urm, U, S, Vt, uTest, K, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:38:50.376825Z",
     "start_time": "2017-09-26T05:38:48.031969Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for user in uTest:\n",
    "    print(\"当前待推荐用户编号 {}\". format(user))\n",
    "    rank_value = 1\n",
    "    for i in uTest_recommended_items[user,0:10]:\n",
    "        song_details = small_set[small_set.so_index_value == i].drop_duplicates('so_index_value')[['title','artist_name']]\n",
    "        print(\"推荐编号： {} 推荐歌曲： {} 作者： {}\".format(rank_value, list(song_details['title'])[0],list(song_details['artist_name'])[0]))\n",
    "        rank_value+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里对每一个用户都得到了其对应的推荐结果，并且将结果按照得分值进行排序。\n",
    "\n",
    "\n",
    "本章我们选择了音乐数据集来进行个性化推荐任务，首先对数据进行预处理和整合，选择两种方法分别完成推荐任务。在相似度计算中根据用户所听过的歌曲在候选集中选择与其最相似的歌曲，存在的问题就是计算时间消耗太多，每一个用户都需要重新计算一遍才能得出推荐结果。在SVD矩阵分解的方法中，我们首先构建评分矩阵，对其进行SVD分解，然后选择待推荐用户，还原得到其对所有歌曲的估测评分值，最后排序返回结果即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:37:37.485771Z",
     "start_time": "2017-09-26T05:37:37.387208Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "uTest = [27513]\n",
    "#Get estimated rating for test user\n",
    "print(\"Predictied ratings:\")\n",
    "uTest_recommended_items = compute_estimated_matrix(urm, U, S, Vt, uTest, K, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-26T05:37:38.879475Z",
     "start_time": "2017-09-26T05:37:38.540521Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for user in uTest:\n",
    "    print(\"当前待推荐用户编号 {}\". format(user))\n",
    "    rank_value = 1\n",
    "    for i in uTest_recommended_items[user,0:10]:\n",
    "        song_details = small_set[small_set.so_index_value == i].drop_duplicates('so_index_value')[['title','artist_name']]\n",
    "        print(\"推荐编号： {} 推荐歌曲： {} 作者： {}\".format(rank_value, list(song_details['title'])[0],list(song_details['artist_name'])[0]))\n",
    "        rank_value+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "nav_menu": {
    "height": "153px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {
    "height": "691px",
    "left": "0px",
    "right": "1405px",
    "top": "106px",
    "width": "303px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}